# 1. Language Processing and Python
## 1 Computing with Language: Texts and Words
### 1.1 Getting Started with Python

### 1.2 Getting Started with NLTK

```python
>>> from nltk.book import *
```
### 1.3 Searching Text

```python
>>> text1.concordance("monstrous")
>>> text1.similar("monstrous")
>>> text1.common_contexts(["monstrous", "very"])
>>> text4.dispersion_plot(["citizens", "democracy", "freedom", "duties", "America"])
```

### 1.4 Counting Vocabulary

```python
>>> len(text3)
>>> sorted(set(text3))
>>> len(set(text3))
>>> len(set(text3)) / len(text3)
>>> text3.count("smote")
```

```python
>>> def lexical_diversity(text): 
...     return len(set(text)) / len(text)
...
>>> def percentage(count, total):
...     return 100 * count / total
...
```

## 2 A Closer Look at Python: Texts as Lists of Words

## 3 Computing with Language: Simple Statistics

### 3.1 Frequency Distributions

```python
>>> fdist1 = FreqDist(text1)
>>> fdist1.most_common(50)
>>> fdist1.plot(50, cumulative=True)
```

### 3.2 Fine-grained Selection of Words

  (1) a. $\{w | w \in V \& P(w)\}$   
      b. [w for w in V if p(w)]

```python
>>> V = set(text1)
>>> long_words = [w for w in V if len(w) > 15]
>>> sorted(long_words)
```

### 3.3 Collocations and Bigrams

**collocation** a sequence of words that occur together unusually often.

**bigrams** list of word pairs

```python
>>> list(bigrams(text))
>>> text.collocation()
```

### 3.4 Counting Other Things

```python
>>> [len(w) for w in text1]
>>> fdist = FreqDist(len(w) for w in text1)
```

#### Functions Defined for NLTK's Frequency Distribution
| Example	| Description |
| ---- | ---- |
| `fdist = FreqDist(samples)` | create a frequency distribution containing the given samples |
| `fdist[sample] += 1` | increment the count for this sample |
| `fdist['monstrous']` | count of the number of times a given sample occurred |
| `fdist.freq('monstrous')` | frequency of a given sample |
| `fdist.N()` | total number of samples |
| `fdist.most_common(n)` |	the n most common samples and their frequencies |
| `for sample in fdist:` |	iterate over the samples |
| `fdist.max()` | sample with the greatest count |
| `fdist.tabulate()` | tabulate the frequency distribution |
| `fdist.plot()` | graphical plot of the frequency distribution |
| `fdist.plot(cumulative=True)` | cumulative plot of the frequency distribution |
| `fdist1 |= fdist2` | update fdist1 with counts from fdist2 |
| `fdist1 < fdist2` |	test if samples in fdist1 occur less frequently than in fdist2 |

## 4 Back to Python: Making Decisions and Taking Control

## 5 Automatic Natual Language Understanding

### 5.1 Word Sense Disambiguation
### 5.2 Pronoun Resolution
### 5.3 Generating Language Output
### 5.4 Machine Translation

equilibrium

text alignment: capture articles in different languages
### 5.5 Spoken Dialog Systems
[dialog](./images/dialogue.png)


### 5.6 Textual Entailment

Recognizing Textual Entailment (RTE)
 
### 5.5 Lmitations of NLP

common sense reasoning
draw on world knowledge in a general and robust manner

# 6 Summary

# 7 Furtuer Reading

- Indurkhya, Nitin and Fred Damerau (eds, 2010) Handbook of Natural Language Processing (Second Edition) Chapman & Hall/CRC. 2010. (Indurkhya & Damerau, 2010) (Dale, Moisl, & Somers, 2000)
- Jurafsky, Daniel and James Martin (2008) Speech and Language Processing (Second Edition). Prentice Hall. (Jurafsky & Martin, 2008)
- Mitkov, Ruslan (ed, 2003) The Oxford Handbook of Computational Linguistics. Oxford University Press. (second edition expected in 2010). (Mitkov, 2002)
